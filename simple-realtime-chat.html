<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simple Realtime Voice Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            color: white;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            text-align: center;
        }

        .title {
            font-size: 24px;
            margin-bottom: 10px;
            color: #e2e8f0;
        }

        .subtitle {
            color: #94a3b8;
            margin-bottom: 30px;
        }

        .voice-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 36px;
            margin: 20px auto;
            background: linear-gradient(135deg, #1e40af, #3b82f6);
            color: white;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(59, 130, 246, 0.3);
        }

        .voice-button:hover {
            transform: scale(1.05);
        }

        .voice-button.listening {
            background: linear-gradient(135deg, #dc2626, #ef4444);
            animation: pulse 1.5s infinite;
        }

        .voice-button.speaking {
            background: linear-gradient(135deg, #059669, #10b981);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { transform: scale(1.05); box-shadow: 0 0 0 20px rgba(59, 130, 246, 0); }
            100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }

        .status {
            font-size: 16px;
            color: #e2e8f0;
            margin: 10px 0;
        }

        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .control-button {
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            color: white;
            cursor: pointer;
            font-size: 14px;
            transition: background 0.2s;
        }

        .control-button:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .settings {
            margin-top: 30px;
            text-align: left;
        }

        .setting {
            margin-bottom: 15px;
        }

        .setting label {
            display: block;
            font-size: 14px;
            color: #94a3b8;
            margin-bottom: 5px;
        }

        .setting select,
        .setting input,
        .setting textarea {
            width: 100%;
            padding: 8px 12px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 8px;
            color: white;
            font-size: 14px;
        }

        .transcript {
            margin-top: 20px;
            max-height: 200px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 15px;
            text-align: left;
        }

        .transcript-item {
            margin-bottom: 10px;
            padding: 8px;
            border-radius: 8px;
        }

        .transcript-item.user {
            background: rgba(59, 130, 246, 0.2);
            margin-left: 20%;
        }

        .transcript-item.assistant {
            background: rgba(16, 185, 129, 0.2);
            margin-right: 20%;
        }

        .transcript-item.system {
            background: rgba(107, 114, 128, 0.2);
            font-style: italic;
            font-size: 12px;
        }

        .info-box {
            background: rgba(255, 193, 7, 0.1);
            border: 1px solid rgba(255, 193, 7, 0.3);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 20px;
            font-size: 14px;
            color: #fbbf24;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="title">üé§ Simple Realtime Voice Chat</h1>
        <p class="subtitle">Click the microphone and speak naturally</p>

        <div class="info-box">
            <strong>‚úÖ Real OpenAI Integration:</strong> Connected to OpenAI API via Doppler.
            Your voice is transcribed and sent to GPT-4 for real responses.
        </div>

        <button id="voiceButton" class="voice-button" onclick="toggleVoice()">
            üé§
        </button>

        <div id="status" class="status">Click to start conversation</div>

        <div class="settings">
            <div class="setting">
                <label>Voice:</label>
                <select id="voiceSelect">
                    <option value="alloy">Alloy (Neutral)</option>
                    <option value="echo">Echo (Male)</option>
                    <option value="shimmer">Shimmer (Female)</option>
                </select>
            </div>

            <div class="setting">
                <label>Conversation Style:</label>
                <select id="styleSelect">
                    <option value="professional">Professional</option>
                    <option value="friendly">Friendly</option>
                    <option value="casual">Casual</option>
                </select>
            </div>
        </div>

        <div class="transcript" id="transcript">
            <div class="transcript-item system">
                Ready for conversation. Click the microphone to begin.
            </div>
        </div>

        <div class="controls">
            <button class="control-button" onclick="clearTranscript()">Clear</button>
            <button class="control-button" onclick="downloadTranscript()">Download</button>
        </div>
    </div>

    <script>
        class SimpleRealtimeVoiceChat {
            constructor() {
                this.isRecording = false;
                this.recognition = null;
                this.transcript = [];
                this.voice = 'alloy';
                this.style = 'professional';

                this.initElements();
                this.initSpeechRecognition();
            }

            initElements() {
                this.voiceButton = document.getElementById('voiceButton');
                this.status = document.getElementById('status');
                this.transcriptEl = document.getElementById('transcript');
                this.voiceSelect = document.getElementById('voiceSelect');
                this.styleSelect = document.getElementById('styleSelect');

                this.voiceSelect.addEventListener('change', (e) => {
                    this.voice = e.target.value;
                });

                this.styleSelect.addEventListener('change', (e) => {
                    this.style = e.target.value;
                });
            }

            initSpeechRecognition() {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    this.recognition = new SpeechRecognition();
                    this.recognition.continuous = true;
                    this.recognition.interimResults = true;
                    this.recognition.lang = 'en-US';

                    this.recognition.onresult = (event) => {
                        const transcript = Array.from(event.results)
                            .map(result => result[0].transcript)
                            .join('');

                        // Show interim results
                        if (event.results[event.results.length - 1].isFinal) {
                            this.handleUserInput(transcript);
                        }
                    };

                    this.recognition.onerror = (event) => {
                        console.error('Speech recognition error:', event.error);
                        this.addTranscriptItem('system', `Speech error: ${event.error}`);
                        this.stopRecording();
                    };

                    this.recognition.onend = () => {
                        if (this.isRecording) {
                            // Restart if still recording
                            this.recognition.start();
                        }
                    };

                } else {
                    console.warn('Speech recognition not supported');
                    this.addTranscriptItem('system', 'Speech recognition not supported in this browser');
                }
            }

            async toggleVoice() {
                if (this.isRecording) {
                    this.stopRecording();
                } else {
                    await this.startRecording();
                }
            }

            async startRecording() {
                if (!this.recognition) {
                    this.addTranscriptItem('system', 'Speech recognition not available');
                    return;
                }

                this.isRecording = true;
                this.voiceButton.className = 'voice-button listening';
                this.status.textContent = 'Listening...';

                try {
                    this.recognition.start();
                    this.addTranscriptItem('system', 'üé§ Listening... Speak naturally');
                } catch (error) {
                    console.error('Error starting recognition:', error);
                    this.addTranscriptItem('system', `Error: ${error.message}`);
                    this.stopRecording();
                }
            }

            stopRecording() {
                this.isRecording = false;
                this.voiceButton.className = 'voice-button';
                this.status.textContent = 'Processing...';

                if (this.recognition) {
                    this.recognition.stop();
                }

                // Simulate AI response after a delay
                setTimeout(() => {
                    this.simulateAIResponse();
                }, 1000);
            }

            handleUserInput(text) {
                this.addTranscriptItem('user', text);
                console.log('User said:', text);
            }

            async simulateAIResponse() {
                // This will now make REAL OpenAI API calls
                await this.getAIResponse();
            }

            async getAIResponse() {
                try {
                    this.voiceButton.className = 'voice-button speaking';
                    this.status.textContent = 'AI thinking...';

                    // Get the last user message
                    const userMessages = this.transcript
                        .filter(item => item.speaker === 'user')
                        .map(item => item.text);

                    if (userMessages.length === 0) {
                        this.addTranscriptItem('system', 'No user message to process');
                        return;
                    }

                    const lastUserMessage = userMessages[userMessages.length - 1];

                    // Call our server endpoint which will use OpenAI API
                    const response = await fetch('/chat-completion', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            message: lastUserMessage,
                            voice: this.voice,
                            style: this.style,
                            conversation_history: this.transcript
                                .filter(item => item.speaker !== 'system')
                                .slice(-6) // Last 6 messages for context
                        })
                    });

                    if (!response.ok) {
                        throw new Error('Failed to get AI response');
                    }

                    const data = await response.json();
                    const aiResponse = data.response;

                    this.addTranscriptItem('assistant', aiResponse);
                    this.status.textContent = 'Ready for next input';

                    // Simulate audio playback duration
                    setTimeout(() => {
                        this.voiceButton.className = 'voice-button';
                        this.status.textContent = 'Ready for next input';
                    }, 2000);

                } catch (error) {
                    console.error('Error getting AI response:', error);
                    this.addTranscriptItem('system', `‚ùå AI Error: ${error.message}`);
                    this.status.textContent = 'Error occurred';
                    this.voiceButton.className = 'voice-button';
                }
            }

            addTranscriptItem(speaker, text) {
                const item = document.createElement('div');
                item.className = `transcript-item ${speaker}`;
                item.textContent = text;

                this.transcriptEl.appendChild(item);
                this.transcriptEl.scrollTop = this.transcriptEl.scrollHeight;

                this.transcript.push({ speaker, text, timestamp: new Date() });
            }

            clearTranscript() {
                this.transcriptEl.innerHTML = '<div class="transcript-item system">Ready for conversation. Click the microphone to begin.</div>';
                this.transcript = [];
            }

            downloadTranscript() {
                const text = this.transcript.map(item =>
                    `[${item.timestamp.toLocaleString()}] ${item.speaker.toUpperCase()}: ${item.text}`
                ).join('\n\n');

                const blob = new Blob([text], { type: 'text/plain' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `voice-chat-${new Date().toISOString().slice(0, 19)}.txt`;
                a.click();
                URL.revokeObjectURL(url);
            }
        }

        // Global functions
        let voiceChat;

        function toggleVoice() {
            voiceChat.toggleVoice();
        }

        function clearTranscript() {
            voiceChat.clearTranscript();
        }

        function downloadTranscript() {
            voiceChat.downloadTranscript();
        }

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', () => {
            voiceChat = new SimpleRealtimeVoiceChat();
        });
    </script>
</body>
</html>